{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true,
      "history_visible": true,
      "authorship_tag": "ABX9TyMKZhe/AGfX0EF2OZeHeH5Z",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/pjh7/Onsets_Frames_and_Pedals/blob/main/melspec_input.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Google Drive에 연결"
      ],
      "metadata": {
        "id": "jnq1Au4CcQi_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "K_e0xmF4cKBP",
        "outputId": "f579da11-22a6-4db1-e046-66adfec2c887"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%cd drive/MyDrive/Colab Notebooks"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vcicCgnycKjW",
        "outputId": "0fcc12fa-d8e3-4a7e-e1d7-3eda43cb6e3c"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/drive/MyDrive/Colab Notebooks\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Package 설치"
      ],
      "metadata": {
        "id": "ZVHJzro_eBEp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os, sys\n",
        "\n",
        "my_path = '/content/package'\n",
        "save_path = '/content/drive/MyDrive/Colab Notebooks/package' ## 패키지가 저장될 경로\n",
        "\n",
        "if os.path.exists(my_path):\n",
        "  os.unlink(my_path)\n",
        "os.symlink(save_path, my_path)\n",
        "sys.path.insert(0, my_path)\n",
        "\n",
        "!pip install --target=$my_path import_ipynb\n",
        "!pip install --target=$my_path tensorflow"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "x_er9FEtdLxQ",
        "outputId": "b12e31d2-77de-4ca9-d347-c0fff698eb52"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting import_ipynb\n",
            "  Using cached import_ipynb-0.1.4-py3-none-any.whl (4.1 kB)\n",
            "Collecting IPython (from import_ipynb)\n",
            "  Using cached ipython-8.20.0-py3-none-any.whl (809 kB)\n",
            "Collecting nbformat (from import_ipynb)\n",
            "  Using cached nbformat-5.9.2-py3-none-any.whl (77 kB)\n",
            "Collecting decorator (from IPython->import_ipynb)\n",
            "  Using cached decorator-5.1.1-py3-none-any.whl (9.1 kB)\n",
            "Collecting jedi>=0.16 (from IPython->import_ipynb)\n",
            "  Using cached jedi-0.19.1-py2.py3-none-any.whl (1.6 MB)\n",
            "Collecting matplotlib-inline (from IPython->import_ipynb)\n",
            "  Using cached matplotlib_inline-0.1.6-py3-none-any.whl (9.4 kB)\n",
            "Collecting prompt-toolkit<3.1.0,>=3.0.41 (from IPython->import_ipynb)\n",
            "  Using cached prompt_toolkit-3.0.43-py3-none-any.whl (386 kB)\n",
            "Collecting pygments>=2.4.0 (from IPython->import_ipynb)\n",
            "  Using cached pygments-2.17.2-py3-none-any.whl (1.2 MB)\n",
            "Collecting stack-data (from IPython->import_ipynb)\n",
            "  Using cached stack_data-0.6.3-py3-none-any.whl (24 kB)\n",
            "Collecting traitlets>=5 (from IPython->import_ipynb)\n",
            "  Using cached traitlets-5.14.1-py3-none-any.whl (85 kB)\n",
            "Collecting exceptiongroup (from IPython->import_ipynb)\n",
            "  Using cached exceptiongroup-1.2.0-py3-none-any.whl (16 kB)\n",
            "\u001b[31mERROR: Operation cancelled by user\u001b[0m\u001b[31m\n",
            "\u001b[0mTraceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pip/_internal/cli/base_command.py\", line 169, in exc_logging_wrapper\n",
            "    status = run_func(*args)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pip/_internal/cli/req_command.py\", line 242, in wrapper\n",
            "    return func(self, options, args)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pip/_internal/commands/install.py\", line 377, in run\n",
            "    requirement_set = resolver.resolve(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pip/_internal/resolution/resolvelib/resolver.py\", line 92, in resolve\n",
            "    result = self._result = resolver.resolve(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pip/_vendor/resolvelib/resolvers.py\", line 546, in resolve\n",
            "    state = resolution.resolve(requirements, max_rounds=max_rounds)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pip/_vendor/resolvelib/resolvers.py\", line 427, in resolve\n",
            "    failure_causes = self._attempt_to_pin_criterion(name)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pip/_vendor/resolvelib/resolvers.py\", line 239, in _attempt_to_pin_criterion\n",
            "    criteria = self._get_updated_criteria(candidate)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pip/_vendor/resolvelib/resolvers.py\", line 230, in _get_updated_criteria\n",
            "    self._add_to_criteria(criteria, requirement, parent=candidate)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pip/_vendor/resolvelib/resolvers.py\", line 173, in _add_to_criteria\n",
            "    if not criterion.candidates:\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pip/_vendor/resolvelib/structs.py\", line 156, in __bool__\n",
            "    return bool(self._sequence)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pip/_internal/resolution/resolvelib/found_candidates.py\", line 155, in __bool__\n",
            "    return any(self)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pip/_internal/resolution/resolvelib/found_candidates.py\", line 143, in <genexpr>\n",
            "    return (c for c in iterator if id(c) not in self._incompatible_ids)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pip/_internal/resolution/resolvelib/found_candidates.py\", line 47, in _iter_built\n",
            "    candidate = func()\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pip/_internal/resolution/resolvelib/factory.py\", line 206, in _make_candidate_from_link\n",
            "    self._link_candidate_cache[link] = LinkCandidate(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pip/_internal/resolution/resolvelib/candidates.py\", line 293, in __init__\n",
            "    super().__init__(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pip/_internal/resolution/resolvelib/candidates.py\", line 156, in __init__\n",
            "    self.dist = self._prepare()\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pip/_internal/resolution/resolvelib/candidates.py\", line 225, in _prepare\n",
            "    dist = self._prepare_distribution()\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pip/_internal/resolution/resolvelib/candidates.py\", line 304, in _prepare_distribution\n",
            "    return preparer.prepare_linked_requirement(self._ireq, parallel_builds=True)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pip/_internal/operations/prepare.py\", line 516, in prepare_linked_requirement\n",
            "    return self._prepare_linked_requirement(req, parallel_builds)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pip/_internal/operations/prepare.py\", line 631, in _prepare_linked_requirement\n",
            "    dist = _get_prepared_distribution(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pip/_internal/operations/prepare.py\", line 68, in _get_prepared_distribution\n",
            "    with build_tracker.track(req):\n",
            "  File \"/usr/lib/python3.10/contextlib.py\", line 135, in __enter__\n",
            "    return next(self.gen)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pip/_internal/operations/build/build_tracker.py\", line 122, in track\n",
            "    self.add(req)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pip/_internal/operations/build/build_tracker.py\", line 102, in add\n",
            "    logger.debug(\"Added %s to build tracker %r\", req, self._root)\n",
            "  File \"/usr/lib/python3.10/logging/__init__.py\", line 1465, in debug\n",
            "    self._log(DEBUG, msg, args, **kwargs)\n",
            "  File \"/usr/lib/python3.10/logging/__init__.py\", line 1624, in _log\n",
            "    self.handle(record)\n",
            "  File \"/usr/lib/python3.10/logging/__init__.py\", line 1634, in handle\n",
            "    self.callHandlers(record)\n",
            "  File \"/usr/lib/python3.10/logging/__init__.py\", line 1696, in callHandlers\n",
            "    hdlr.handle(record)\n",
            "  File \"/usr/lib/python3.10/logging/__init__.py\", line 968, in handle\n",
            "    self.emit(record)\n",
            "  File \"/usr/lib/python3.10/logging/handlers.py\", line 75, in emit\n",
            "    logging.FileHandler.emit(self, record)\n",
            "  File \"/usr/lib/python3.10/logging/__init__.py\", line 1218, in emit\n",
            "    StreamHandler.emit(self, record)\n",
            "  File \"/usr/lib/python3.10/logging/__init__.py\", line 1104, in emit\n",
            "    self.flush()\n",
            "  File \"/usr/lib/python3.10/logging/__init__.py\", line 1084, in flush\n",
            "    self.stream.flush()\n",
            "KeyboardInterrupt\n",
            "\n",
            "During handling of the above exception, another exception occurred:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/bin/pip3\", line 8, in <module>\n",
            "    sys.exit(main())\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pip/_internal/cli/main.py\", line 79, in main\n",
            "    return command.main(cmd_args)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pip/_internal/cli/base_command.py\", line 101, in main\n",
            "    return self._main(args)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pip/_internal/cli/base_command.py\", line 223, in _main\n",
            "    return run(options, args)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pip/_internal/cli/base_command.py\", line 206, in exc_logging_wrapper\n",
            "    logger.critical(\"Operation cancelled by user\")\n",
            "  File \"/usr/lib/python3.10/logging/__init__.py\", line 1524, in critical\n",
            "    self._log(CRITICAL, msg, args, **kwargs)\n",
            "  File \"/usr/lib/python3.10/logging/__init__.py\", line 1624, in _log\n",
            "    self.handle(record)\n",
            "  File \"/usr/lib/python3.10/logging/__init__.py\", line 1634, in handle\n",
            "    self.callHandlers(record)\n",
            "  File \"/usr/lib/python3.10/logging/__init__.py\", line 1696, in callHandlers\n",
            "    hdlr.handle(record)\n",
            "  File \"/usr/lib/python3.10/logging/__init__.py\", line 968, in handle\n",
            "    self.emit(record)\n",
            "  File \"/usr/lib/python3.10/logging/handlers.py\", line 75, in emit\n",
            "    logging.FileHandler.emit(self, record)\n",
            "  File \"/usr/lib/python3.10/logging/__init__.py\", line 1218, in emit\n",
            "    StreamHandler.emit(self, record)\n",
            "  File \"/usr/lib/python3.10/logging/__init__.py\", line 1100, in emit\n",
            "    msg = self.format(record)\n",
            "  File \"/usr/lib/python3.10/logging/__init__.py\", line 943, in format\n",
            "    return fmt.format(record)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pip/_internal/utils/logging.py\", line 118, in format\n",
            "    prefix = f\"{self.formatTime(record)} \"\n",
            "  File \"/usr/lib/python3.10/logging/__init__.py\", line 615, in formatTime\n",
            "    ct = self.converter(record.created)\n",
            "KeyboardInterrupt\n",
            "^C\n",
            "Collecting tensorflow\n",
            "\u001b[31mERROR: Operation cancelled by user\u001b[0m\u001b[31m\n",
            "\u001b[0m"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "d2l1Jv8IVDbj"
      },
      "outputs": [],
      "source": [
        "# Copyright 2023 The Magenta Authors.\n",
        "#\n",
        "# Licensed under the Apache License, Version 2.0 (the \"License\");\n",
        "# you may not use this file except in compliance with the License.\n",
        "# You may obtain a copy of the License at\n",
        "#\n",
        "#     http://www.apache.org/licenses/LICENSE-2.0\n",
        "#\n",
        "# Unless required by applicable law or agreed to in writing, software\n",
        "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
        "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
        "# See the License for the specific language governing permissions and\n",
        "# limitations under the License.\n",
        "\n",
        "\"\"\"Create TF graphs for calculating log-mel-spectral features.\n",
        "\n",
        "NOTE: This code is very experimental and will likely change, both in interface\n",
        "and what it outputs.\n",
        "\n",
        "The single published method is build_mel_calculation_graph, which\n",
        "will assemble a TF graph from a provided waveform input vector\n",
        "through to a (num_frames, frame_width, num_mel_bins) tensor of log-\n",
        "transformed mel spectrogram patches, suitable for feeding the input\n",
        "to a typical classifier. All the mel calculation parameters\n",
        "are available as options, but default to their standard values\n",
        "(e.g. frame_width=96, frame_hop=10). The input waveform can have\n",
        "size (None,), meaning it will be specified at run-time.\n",
        "\n",
        "with tflite_compatible=True, the returned graph is constructed only\n",
        "from tflite-compatible ops (i.e., it uses matmul for the DFT, and\n",
        "explicitly unrolled framing). In this case, the input waveform tensor\n",
        "must have an explicit size at graph-building time.\n",
        "\"\"\"\n",
        "\n",
        "import math\n",
        "import import_ipynb\n",
        "\n",
        "import mfcc_mel\n",
        "import numpy as np\n",
        "import tensorflow.compat.v1 as tf\n",
        "\n",
        "\n",
        "def _stft_magnitude_full_tf(waveform_input, window_length_samples,\n",
        "                            hop_length_samples, fft_length):\n",
        "  \"\"\"Calculate STFT magnitude (spectrogram) using tf.signal ops.\"\"\"\n",
        "  stft_magnitude = tf.abs(                                             # tf.abs: absolute value\n",
        "      tf.signal.stft(\n",
        "          # tf.signal.stft(signals, frame_length, frame_step, fft_length=None, window_fn=window_ops.hann_window, pad_end=False, name=None): stft\n",
        "          # output: signal이 2개 이상일 경우 각각의 signal에 대해 stft를 진행하면 2차원 행렬들이 나오므로, 그것을 모으면 3차원 텐서가 된다.\n",
        "          waveform_input,\n",
        "          frame_length=window_length_samples,\n",
        "          frame_step=hop_length_samples,\n",
        "          fft_length=fft_length),\n",
        "      name='magnitude_spectrogram')\n",
        "  return stft_magnitude\n",
        "\n",
        "\n",
        "def _dft_matrix(dft_length):\n",
        "  \"\"\"Calculate the full DFT matrix in numpy.\"\"\"\n",
        "  omega = (0 + 1j) * 2.0 * np.pi / float(dft_length)\n",
        "  # Don't include 1/sqrt(N) scaling, tf.signal.rfft doesn't apply it.\n",
        "  return np.exp(omega * np.outer(np.arange(dft_length), np.arange(dft_length)))\n",
        "\n",
        "\n",
        "def _naive_rdft(signal_tensor, fft_length):\n",
        "  \"\"\"Implement real-input Fourier Transform by matmul.\"\"\"\n",
        "  # We are right-multiplying by the DFT matrix, and we are keeping\n",
        "  # only the first half (\"positive frequencies\").\n",
        "  # So discard the second half of rows, but transpose the array for\n",
        "  # right-multiplication.\n",
        "  # The DFT matrix is symmetric, so we could have done it more\n",
        "  # directly, but this reflects our intention better.\n",
        "  complex_dft_matrix_kept_values = _dft_matrix(fft_length)[:(\n",
        "      fft_length // 2 + 1), :].transpose()\n",
        "  real_dft_tensor = tf.constant(\n",
        "      np.real(complex_dft_matrix_kept_values).astype(np.float32),\n",
        "      name='real_dft_matrix')\n",
        "  imag_dft_tensor = tf.constant(\n",
        "      np.imag(complex_dft_matrix_kept_values).astype(np.float32),\n",
        "      name='imaginary_dft_matrix')\n",
        "  signal_frame_length = int(signal_tensor.shape[-1])\n",
        "  half_pad = (fft_length - signal_frame_length) // 2\n",
        "  pad_values = tf.concat([\n",
        "      tf.zeros([tf.rank(signal_tensor) - 1, 2], tf.int32),\n",
        "      [[half_pad, fft_length - signal_frame_length - half_pad]]\n",
        "  ],\n",
        "                         axis=0)\n",
        "  padded_signal = tf.pad(signal_tensor, pad_values)\n",
        "  result_real_part = tf.matmul(padded_signal, real_dft_tensor)\n",
        "  result_imag_part = tf.matmul(padded_signal, imag_dft_tensor)\n",
        "  return result_real_part, result_imag_part\n",
        "\n",
        "\n",
        "def _fixed_frame(signal, frame_length, frame_step, first_axis=False):\n",
        "  \"\"\"tflite-compatible tf.signal.frame for fixed-size input.\n",
        "\n",
        "  Args:\n",
        "    signal: Tensor containing signal(s).\n",
        "    frame_length: Number of samples to put in each frame.\n",
        "    frame_step: Sample advance between successive frames.\n",
        "    first_axis: If true, framing is applied to first axis of tensor; otherwise,\n",
        "      it is applied to last axis.\n",
        "\n",
        "  Returns:\n",
        "    A new tensor where the last axis (or first, if first_axis) of input\n",
        "    signal has been replaced by a (num_frames, frame_length) array of individual\n",
        "    frames where each frame is drawn frame_step samples after the previous one.\n",
        "\n",
        "  Raises:\n",
        "    ValueError: if signal has an undefined axis length.  This routine only\n",
        "      supports framing of signals whose shape is fixed at graph-build time.\n",
        "  \"\"\"\n",
        "  signal_shape = signal.shape.as_list()\n",
        "  if first_axis:\n",
        "    length_samples = signal_shape[0]\n",
        "  else:\n",
        "    length_samples = signal_shape[-1]\n",
        "  if length_samples <= 0:\n",
        "    raise ValueError('fixed framing requires predefined constant signal length')\n",
        "  num_frames = max(0, 1 + (length_samples - frame_length) // frame_step)\n",
        "  if first_axis:\n",
        "    inner_dimensions = signal_shape[1:]\n",
        "    result_shape = [num_frames, frame_length] + inner_dimensions\n",
        "    gather_axis = 0\n",
        "  else:\n",
        "    outer_dimensions = signal_shape[:-1]\n",
        "    result_shape = outer_dimensions + [num_frames, frame_length]\n",
        "    # Currently tflite's gather only supports axis==0, but that may still\n",
        "    # work if we want the last of 1 axes.\n",
        "    gather_axis = len(outer_dimensions)\n",
        "\n",
        "  subframe_length = math.gcd(frame_length, frame_step)\n",
        "  subframes_per_frame = frame_length // subframe_length\n",
        "  subframes_per_hop = frame_step // subframe_length\n",
        "  num_subframes = length_samples // subframe_length\n",
        "\n",
        "  if first_axis:\n",
        "    trimmed_input_size = [num_subframes * subframe_length] + inner_dimensions\n",
        "    subframe_shape = [num_subframes, subframe_length] + inner_dimensions\n",
        "  else:\n",
        "    trimmed_input_size = outer_dimensions + [num_subframes * subframe_length]\n",
        "    subframe_shape = outer_dimensions + [num_subframes, subframe_length]\n",
        "  subframes = tf.reshape(\n",
        "      tf.slice(\n",
        "          signal,\n",
        "          begin=np.zeros(len(signal_shape), np.int32),\n",
        "          size=trimmed_input_size), subframe_shape)\n",
        "\n",
        "  # frame_selector is a [num_frames, subframes_per_frame] tensor\n",
        "  # that indexes into the appropriate frame in subframes. For example:\n",
        "  # [[0, 0, 0, 0], [2, 2, 2, 2], [4, 4, 4, 4]]\n",
        "  frame_selector = np.reshape(\n",
        "      np.arange(num_frames) * subframes_per_hop, [num_frames, 1])\n",
        "\n",
        "  # subframe_selector is a [num_frames, subframes_per_frame] tensor\n",
        "  # that indexes into the appropriate subframe within a frame. For example:\n",
        "  # [[0, 1, 2, 3], [0, 1, 2, 3], [0, 1, 2, 3]]\n",
        "  subframe_selector = np.reshape(\n",
        "      np.arange(subframes_per_frame), [1, subframes_per_frame])\n",
        "\n",
        "  # Adding the 2 selector tensors together produces a [num_frames,\n",
        "  # subframes_per_frame] tensor of indices to use with tf.gather to select\n",
        "  # subframes from subframes. We then reshape the inner-most subframes_per_frame\n",
        "  # dimension to stitch the subframes together into frames. For example:\n",
        "  # [[0, 1, 2, 3], [2, 3, 4, 5], [4, 5, 6, 7]].\n",
        "  selector = frame_selector + subframe_selector\n",
        "  frames = tf.reshape(\n",
        "      tf.gather(subframes, selector.astype(np.int32), axis=gather_axis),\n",
        "      result_shape)\n",
        "  return frames\n",
        "\n",
        "\n",
        "def _stft_tflite(signal, frame_length, frame_step, fft_length):\n",
        "  \"\"\"tflite-compatible implementation of tf.signal.stft.\n",
        "\n",
        "  Compute the short-time Fourier transform of a 1D input while avoiding tf ops\n",
        "  that are not currently supported in tflite (Rfft, Range, SplitV).\n",
        "  fft_length must be fixed. A Hann window is of frame_length is always\n",
        "  applied.\n",
        "\n",
        "  Since fixed (precomputed) framing must be used, signal.shape[-1] must be a\n",
        "  specific value (so \"?\"/None is not supported).\n",
        "\n",
        "  Args:\n",
        "    signal: 1D tensor containing the time-domain waveform to be transformed.\n",
        "    frame_length: int, the number of points in each Fourier frame.\n",
        "    frame_step: int, the number of samples to advance between successive frames.\n",
        "    fft_length: int, the size of the Fourier transform to apply.\n",
        "\n",
        "  Returns:\n",
        "    Two (num_frames, fft_length) tensors containing the real and imaginary parts\n",
        "    of the short-time Fourier transform of the input signal.\n",
        "  \"\"\"\n",
        "  # Make the window be shape (1, frame_length) instead of just frame_length\n",
        "  # in an effort to help the tflite broadcast logic.\n",
        "  window = tf.reshape(\n",
        "      tf.constant(\n",
        "          (0.5 - 0.5 * np.cos(2 * np.pi * np.arange(0, 1.0, 1.0 / frame_length))\n",
        "          ).astype(np.float32),\n",
        "          name='window'), [1, frame_length])\n",
        "  framed_signal = _fixed_frame(\n",
        "      signal, frame_length, frame_step, first_axis=False)\n",
        "  framed_signal *= window\n",
        "  real_spectrogram, imag_spectrogram = _naive_rdft(framed_signal, fft_length)\n",
        "  return real_spectrogram, imag_spectrogram\n",
        "\n",
        "\n",
        "def _stft_magnitude_tflite(waveform_input, window_length_samples,\n",
        "                           hop_length_samples, fft_length):\n",
        "  \"\"\"Calculate spectrogram avoiding tflite incompatible ops.\"\"\"\n",
        "  real_stft, imag_stft = _stft_tflite(\n",
        "      waveform_input,\n",
        "      frame_length=window_length_samples,\n",
        "      frame_step=hop_length_samples,\n",
        "      fft_length=fft_length)\n",
        "  stft_magnitude = tf.sqrt(\n",
        "      tf.add(real_stft * real_stft, imag_stft * imag_stft),\n",
        "      name='magnitude_spectrogram')\n",
        "  return stft_magnitude\n",
        "\n",
        "\n",
        "def build_mel_calculation_graph(waveform_input,\n",
        "                                sample_rate=16000,\n",
        "                                window_length_seconds=0.025,\n",
        "                                hop_length_seconds=0.010,\n",
        "                                num_mel_bins=64,\n",
        "                                lower_edge_hz=125.0,\n",
        "                                upper_edge_hz=7500.0,\n",
        "                                frame_width=96,\n",
        "                                frame_hop=10,\n",
        "                                tflite_compatible=False):\n",
        "  \"\"\"Build a TF graph to go from waveform to mel spectrum patches.\n",
        "\n",
        "  Args:\n",
        "    waveform_input: 1D Tensor which will be filled with 16 kHz waveform as\n",
        "      tf.float32.\n",
        "    sample_rate: Scalar giving the sampling rate of the waveform.  Only 16 kHz\n",
        "      is acceptable at present.\n",
        "    window_length_seconds: Duration of window used for each Fourier transform.\n",
        "    hop_length_seconds: Time shift between successive analysis time frames.\n",
        "    num_mel_bins: The number of mel frequency bins to calculate.\n",
        "    lower_edge_hz: Frequency boundary at bottom edge of mel mapping.\n",
        "    upper_edge_hz: Frequency boundary at top edge of mel mapping.\n",
        "    frame_width: The number of successive time frames to include in each patch.\n",
        "    frame_hop: The frame advance between successive patches.\n",
        "    tflite_compatible: Avoid ops not currently supported in tflite.\n",
        "\n",
        "  Returns:\n",
        "    Tensor holding [num_patches, frame_width, num_mel_bins] log-mel-spectrogram\n",
        "    patches.\n",
        "  \"\"\"\n",
        "  # `waveform_input` is a [?] vector as a tensor.\n",
        "  # `magnitude_spectrogram` is a [?, fft_length/2 + 1] tensor of spectrograms.\n",
        "  # Derive the dependent parameters.\n",
        "  window_length_samples = int(round(window_length_seconds * sample_rate))\n",
        "  hop_length_samples = int(round(hop_length_seconds * sample_rate))\n",
        "  fft_length = 2**int(\n",
        "      math.ceil(math.log(window_length_samples) / math.log(2.0)))\n",
        "  if tflite_compatible:\n",
        "    magnitude_spectrogram = _stft_magnitude_tflite(\n",
        "        waveform_input, window_length_samples, hop_length_samples, fft_length)\n",
        "  else:\n",
        "    magnitude_spectrogram = _stft_magnitude_full_tf(\n",
        "        waveform_input, window_length_samples, hop_length_samples, fft_length)\n",
        "\n",
        "  # Warp the linear-scale, magnitude spectrograms into the mel-scale.\n",
        "  num_spectrogram_bins = int(magnitude_spectrogram.shape[-1])\n",
        "  if tflite_compatible:\n",
        "    linear_to_mel_weight_matrix = tf.constant(\n",
        "        mfcc_mel.SpectrogramToMelMatrix(num_mel_bins, num_spectrogram_bins,\n",
        "                                        sample_rate, lower_edge_hz,\n",
        "                                        upper_edge_hz).astype(np.float32),\n",
        "        name='linear_to_mel_matrix')\n",
        "  else:\n",
        "    # In full tf, the mel weight matrix is calculated at run time within the\n",
        "    # TF graph.  This avoids including a matrix of 64 x 256 float values (i.e.,\n",
        "    # 100 kB or more, depending on the representation) in the exported graph.\n",
        "    linear_to_mel_weight_matrix = tf.signal.linear_to_mel_weight_matrix(\n",
        "        num_mel_bins, num_spectrogram_bins, sample_rate, lower_edge_hz,\n",
        "        upper_edge_hz)\n",
        "\n",
        "  mel_spectrogram = tf.matmul(\n",
        "      magnitude_spectrogram,\n",
        "      linear_to_mel_weight_matrix,\n",
        "      name='mel_spectrogram')\n",
        "  log_offset = 0.001\n",
        "  log_mel_spectrogram = tf.log(\n",
        "      mel_spectrogram + log_offset, name='log_mel_spectrogram')\n",
        "  # log_mel_spectrogram is a [?, num_mel_bins] gram.\n",
        "  if tflite_compatible:\n",
        "    features = _fixed_frame(\n",
        "        log_mel_spectrogram,\n",
        "        frame_length=frame_width,\n",
        "        frame_step=frame_hop,\n",
        "        first_axis=True)\n",
        "  else:\n",
        "    features = tf.signal.frame(\n",
        "        log_mel_spectrogram,\n",
        "        frame_length=frame_width,\n",
        "        frame_step=frame_hop,\n",
        "        axis=0)\n",
        "  # features is [num_patches, frame_width, num_mel_bins].\n",
        "  return features"
      ]
    }
  ]
}